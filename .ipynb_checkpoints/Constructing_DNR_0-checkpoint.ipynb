{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the time period ephemeris dataframes\n",
    "\n",
    "This notebook contains the functions that can be used to construct a dataframe that contains the satelltie ephemeris for the time period of interest.\n",
    "\n",
    "\n",
    "**note from zach**:   I made these functions in a slightly cluttered order, and had previously run them in a series of even more cluttered notebooks.  I have gone back through and compiled them all here but I did not go through and organize it.   My apologies. \n",
    "\n",
    "- note 2-- another step that is not included here is that the grace data had to be normalized to 500 km.  I did this and saved each grace file as its own pickle. I can provide these files or try to remmeber to add the code to do that here. TODO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists('E:/data/day_night_data/GRACE_2002_2012/GRACE500km_CombineOrbits.pkl'):\n",
    "#     print('File exists. Hurray!')\n",
    "#     print('E:/data/day_night_data/GRACE_2002_2012/GRACE500km_CombineOrbits')\n",
    "#     Grace500_ts = pd.read_pickle( 'E:/data/day_night_data/GRACE_2002_2012/GRACE500km_CombineOrbits.pkl')  \n",
    "#     pass\n",
    "# else:\n",
    "#     print('Need to combine the separate DataFrames.')\n",
    "#     years =[2002,2003,2004,2005,2006,2007,2008,2009]\n",
    "#     days = np.arange(1,367)\n",
    "\n",
    "#     Grace500_ts = make_grace_timeseries(years, days)\n",
    "#     Grace500_ts.to_pickle( 'E:/data/day_night_data/GRACE_2002_2012/GRACE500km_CombineOrbits.pkl')  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "# print(np.array([0,1,2 ]))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import sys  \n",
    "# sys.path.insert(0, '../')\n",
    "from scipy.io import loadmat  #allows us to read in .mat files\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # identify path to desired data\n",
    "# path = 'E:/data/day_night_data/GRACE_msis/RealF10p7/'\n",
    "# filecheck = 'MSISdf_graceA_500km'\n",
    "\n",
    "# files = ['MSISdf_graceA_500km_20021',\n",
    "#          'MSISdf_graceA_500km_20032',\n",
    "#          'MSISdf_graceA_500km_20043', \n",
    "#          'MSISdf_graceA_500km_20054',\n",
    "#          'MSISdf_graceA_500km_20061'  ,\n",
    "#          'MSISdf_graceA_500km_20072'   ,\n",
    "#          'MSISdf_graceA_500km_20083'  ,\n",
    "#          'MSISdf_graceA_500km_20094' ]\n",
    "\n",
    "# save_file = 'MSISdf_graceA_500km'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "def combine_MSISsampled_dataframes(path, filecheck, files, save_file):\n",
    "\n",
    "    ''' This function combines the dataframes \n",
    "    that were ran and saved separately from the \n",
    "    bootleg paralellization process.\n",
    "    These files contain the MSIS sampled state\n",
    "    at every instance of the satellites orbit'''\n",
    "\n",
    "    if os.path.exists( path + filecheck):\n",
    "        print('File exists. Hurray!')\n",
    "        print(path + filecheck)\n",
    "        pass\n",
    "    else:\n",
    "        print('Need to combine the separate DataFrames.')\n",
    "\n",
    "        for i, val in enumerate(files):\n",
    "            msis_raw = pd.read_pickle(path + val)\n",
    "\n",
    "            index_nonzero = np.nonzero(msis_raw['alt_km'].values)[0]\n",
    "\n",
    "\n",
    "\n",
    "            msis_non_zero = pd.DataFrame(data ={\n",
    "\n",
    "                                       'Year': msis_raw['Year'][index_nonzero],\n",
    "                                       'Doy': msis_raw['Doy'][index_nonzero],\n",
    "                                       'Hours': msis_raw['Hours'][index_nonzero] ,\n",
    "                                       'Date':    msis_raw['Date'][index_nonzero],\n",
    "                                       'alt_km':  msis_raw['alt_km'][index_nonzero],\n",
    "                                       'Lat':     msis_raw['Lat'][index_nonzero],\n",
    "                                       'Lon':     msis_raw['Lon'][index_nonzero],\n",
    "                                       'LocTim':  msis_raw['LocTim'][index_nonzero],\n",
    "                                       'LatBin':  msis_raw['LatBin'][index_nonzero],\n",
    "#                                        'd_n_indicator': d_n_indicator,\n",
    "                                        'Mlat':  msis_raw['Mlat'][index_nonzero], \n",
    "                                        'Mlon': msis_raw['Mlon'][index_nonzero] , \n",
    "                                        'Mlt':  msis_raw['Mlt'][index_nonzero],\n",
    "                                        'U_rho': msis_raw['U_rho'][index_nonzero] ,\n",
    "                                        'Num': msis_raw['Num'][index_nonzero] ,\n",
    "                                        'NumInterp':  msis_raw['NumInterp'][index_nonzero],\n",
    "                                        'Cd': msis_raw['Cd'][index_nonzero] ,  \n",
    "                           # Data Variables\n",
    "                                       'He':   msis_raw['He'][index_nonzero]    ,\n",
    "                                       'O':    msis_raw['O'][index_nonzero]    ,\n",
    "                                       'N2':   msis_raw['N2'][index_nonzero]    , \n",
    "                                       'O2':   msis_raw['O2'][index_nonzero]   ,\n",
    "                                       'Ar':   msis_raw['Ar'][index_nonzero]    , \n",
    "                                       'Dmsis500': msis_raw['Dmsis500'][index_nonzero]  , \n",
    "                                       'DmsisSat': msis_raw['DmsisSat'][index_nonzero]  , \n",
    "                                       'Density_GRACEacc': msis_raw['Density_GRACEacc'][index_nonzero] ,\n",
    "                                       'Height_Sat': msis_raw['Height_Sat'][index_nonzero] ,\n",
    "                                       'Density_GRACED500': msis_raw['Density_GRACED500'][index_nonzero] ,       \n",
    "               \n",
    "                                       'H':      msis_raw['H'][index_nonzero]  , \n",
    "                                       'N':       msis_raw['N'][index_nonzero] , \n",
    "                                       'AnomO':   msis_raw['AnomO'][index_nonzero] ,\n",
    "                                       'Tn':      msis_raw['Tn'][index_nonzero] , \n",
    "                                       'Texo':   msis_raw['Texo'][index_nonzero]  , \n",
    "                                       'H_totalgas' :msis_raw['H_totalgas'][index_nonzero] ,\n",
    "                                       'mbar_totalgas' :msis_raw['mbar_totalgas'][index_nonzero] ,\n",
    "                                    # Attributes\n",
    "                                       'f107s':   msis_raw['f107s'][index_nonzero] , \n",
    "                                       'f107':   msis_raw['f107'][index_nonzero]  , \n",
    "                                       'Ap':     msis_raw['Ap'][index_nonzero]  , \n",
    "                                    # Scale Heights\n",
    "                                        'H_He'    :msis_raw['H_He'][index_nonzero] ,\n",
    "                                        'He_mbar'    :msis_raw['He_mbar'][index_nonzero] ,\n",
    "                                        'H_O'    :msis_raw['H_O'][index_nonzero] ,\n",
    "                                        'O_mbar'    : msis_raw['O_mbar'][index_nonzero],\n",
    "                                        'H_O2'    : msis_raw['H_O2'][index_nonzero],\n",
    "                                        'O2_mbar'    : msis_raw['O2_mbar'][index_nonzero],\n",
    "\n",
    "        \n",
    "                                       }, \n",
    "                                       )\n",
    "\n",
    "            msis_non_zero.to_pickle(path + val + '_non_zeros')\n",
    "\n",
    "        df1 = pd.read_pickle(path + files[0] + '_non_zeros')\n",
    "        df2 = pd.read_pickle(path + files[1] + '_non_zeros')\n",
    "        df3 = pd.read_pickle(path + files[2] + '_non_zeros')\n",
    "        df4 = pd.read_pickle(path + files[3] + '_non_zeros')\n",
    "        df5 = pd.read_pickle(path + files[4] + '_non_zeros')\n",
    "        df6 = pd.read_pickle(path + files[5] + '_non_zeros')\n",
    "        df7 = pd.read_pickle(path + files[6] + '_non_zeros')\n",
    "        df8 = pd.read_pickle(path + files[7] + '_non_zeros')\n",
    "\n",
    "        frame = [df1, df2, df3, df4, df5, df6, df7, df8]\n",
    "\n",
    "        df_combined = pd.concat(frame)\n",
    "\n",
    "        df_combined.to_pickle(path + save_file)\n",
    "\n",
    "\n",
    "# filecheck = '500averages_alt_km'\n",
    "# path = 'E:/data/day_night_data/GRACE_msis/RealF10p7/'\n",
    "# years =  [2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009]\n",
    "# days = np.arange(1,366)\n",
    "# alt = 500\n",
    "\n",
    "def make_MSISsampled_dailyaverages(path, filecheck, years, days, alt, df_msis):\n",
    "\n",
    "    ''' This function takes the combined MSIS state \n",
    "    of the sampled spacecraft and generates daily \n",
    "    averages of the given constituents. '''\n",
    "\n",
    "    constituents = ['alt_km',\n",
    "                    'He',\n",
    "                    'O',\n",
    "                    'Total',\n",
    "#                     'Total500' ,\n",
    "#                     'Total_sat',\n",
    "                    'Tn',\n",
    "                    'H_totalgas',\n",
    "                    'H_He', \n",
    "                    'H_O',\n",
    "                    'mbar_totalgas', \n",
    "                    'He_mbar',\n",
    "                    'O_mbar']\n",
    "    for string in constituents:\n",
    "\n",
    "        exec(\"averages_%s= pd.DataFrame(data = { 'Date':[] ,'DayAverages': [] ,'NightAverages': [] ,'ratio': [],'DayAverages_Masked': [] ,'NightAverages_Masked': [] ,'ratio_Masked': [] ,'f107':[] } )\" % (string))\n",
    "\n",
    "\n",
    "    import os    \n",
    "\n",
    "    if os.path.exists( path + filecheck):\n",
    "        print('File exists. Hurray!')\n",
    "        print(path + filecheck)\n",
    "#         df_msis = pd.read_pickle( path + filecheck)\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        print('File does not exist')\n",
    "        print(path + filecheck)\n",
    "        import pandas as pd\n",
    "        from datetime import datetime\n",
    "        import numpy as np    \n",
    "        import timeit\n",
    "        import time\n",
    "\n",
    "        noaa = pd.read_pickle('E:/data/day_night_data/noaa_2002_2010_pickle' )\n",
    "\n",
    "        Day_SLT1 = 11.5\n",
    "        Day_SLT2 = 17.5\n",
    "\n",
    "        Night_SLT1 = 5.5\n",
    "        Night_SLT2 = 23.5\n",
    "\n",
    "#             years =  [2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009]\n",
    "#             days = np.arange(1,366)\n",
    "        i = 0\n",
    "        for iyear,year in enumerate(years):\n",
    "            for iday,day in enumerate(days):\n",
    "\n",
    "                date_index = datetime(year, 1, 1) + timedelta(float(day) - 1)   \n",
    "                loopindex = np.logical_and(df_msis['year'] == year, df_msis['days'] == day )\n",
    "\n",
    "                mask_day   = np.logical_and(df_msis['SLT'][loopindex] >= 10.5 , df_msis['SLT'][loopindex] <= 16.5)\n",
    "                mask_night = np.logical_or( df_msis['SLT'][loopindex] >= 22.5 , df_msis['SLT'][loopindex] <= 4.5 )  \n",
    "                \n",
    "#                 day_mask =  np.logical_and( champ_df['SLT'] >= Day_SLT1   ,  champ_df['SLT'] <= Day_SLT2) \n",
    "#                 night_mask = np.logical_or((champ_df['SLT'] >= Night_SLT2), (champ_df['SLT'] <= Night_SLT1)) \n",
    "\n",
    "                mask_lats  =  np.logical_and(df_msis['lat'][loopindex] <=30    , df_msis['lat'][loopindex]  >= -30)\n",
    "                mask_Ap    = np.logical_not( df_msis['Ap'][loopindex] >=  15)   \n",
    "\n",
    "\n",
    "                df_loop = pd.DataFrame(data ={\n",
    "        #               # Time (for looping)\n",
    "                            'year': df_msis['year'][loopindex],\n",
    "                            'days' : df_msis['days'][loopindex],\n",
    "                            'time' : df_msis['time'][loopindex],\n",
    "        #               # Coordinates\n",
    "                            'alt_km' : df_msis['alt_km'][loopindex],\n",
    "                            'lat' : df_msis['lat'][loopindex],\n",
    "                            'lon' : df_msis['lon'][loopindex],\n",
    "                            'SLT' : df_msis['SLT'][loopindex],\n",
    "        #               # Atmosphere Species\n",
    "                            'He' : df_msis['He'][loopindex],\n",
    "                            'O' : df_msis['O'][loopindex] ,\n",
    "                            'N2' : df_msis['N2'][loopindex],\n",
    "                            'O2' : df_msis['O2'][loopindex] ,\n",
    "                            'Ar' : df_msis['Ar'][loopindex] ,\n",
    "                            'Total' : df_msis['Total'][loopindex],\n",
    "#                             'Total500' : df_msis['Total500'][loopindex],\n",
    "#                             'Total_sat' : df_msis['Total_sat'][loopindex],\n",
    "                            'H' : df_msis['H'][loopindex],\n",
    "                            'N' : df_msis['N'][loopindex],\n",
    "                            'AnomO' : df_msis['AnomO'][loopindex] ,\n",
    "                            'Tn' : df_msis['Tn'][loopindex] ,\n",
    "                            'Texo' : df_msis['Texo'][loopindex],\n",
    "        #               # Activity indices\n",
    "                            'f107s' : df_msis['f107s'][loopindex],\n",
    "                            'f107' : df_msis['f107'][loopindex],\n",
    "                            'Ap' : df_msis['Ap'][loopindex] ,\n",
    "        #               # Scale Heights\n",
    "                            'H_totalgas' : df_msis['H_totalgas'][loopindex],\n",
    "                            'H_He' : df_msis['H_He'][loopindex],\n",
    "                            'H_O' : df_msis['H_O'][loopindex],\n",
    "        #                     'H_N2' : df_msis['H_N2'][loopindex],\n",
    "        #                     'H_O2' : df_msis['H_O2'][loopindex] ,\n",
    "        #                     'H_Ar' : df_msis['H_Ar'][loopindex],\n",
    "        #                     'H_H' : df_msis['H_H'][loopindex],\n",
    "        #                     'H_N' : df_msis['H_N'][loopindex],\n",
    "        #               # Mean Molecular mass\n",
    "                            'mbar_totalgas' : df_msis['mbar_totalgas'][loopindex],\n",
    "                            'He_mbar' : df_msis['He_mbar'][loopindex],\n",
    "                            'O_mbar' : df_msis['O_mbar'][loopindex],\n",
    "        #                     'N2_mbar' : df_msis['N2_mbar'][loopindex],\n",
    "        #                     'O2_mbar' : df_msis['O2_mbar'][loopindex],\n",
    "        #                     'Ar_mbar' : df_msis['Ar_mbar'][loopindex],\n",
    "        #                     'H_mbar' : df_msis['H_mbar'][loopindex],\n",
    "        #                     'N_mbar' : df_msis['N_mbar'][loopindex],\n",
    "                             }, \n",
    "                             )\n",
    "\n",
    "                for string in constituents:\n",
    "                    df_loop.loc[df_loop[string].notnull(), string+'_days'] = (df_loop[string][mask_day])\n",
    "                    df_loop.loc[df_loop[string].notnull(), string+'_nights'] = (df_loop[string][mask_night])\n",
    "                    df_loop.loc[df_loop[string].notnull(), string+'_days_masked'] = (df_loop[string][mask_day & mask_Ap & mask_lats])\n",
    "                    df_loop.loc[df_loop[string].notnull(), string+'_nights_masked'] = (df_loop[string][mask_night & mask_Ap & mask_lats])\n",
    "\n",
    "\n",
    "                for string in constituents:\n",
    "\n",
    "                    exec(\"averages_%s.loc[i,['Date']] =                 pd.to_datetime(date_index)\"  % (string))\n",
    "                    exec(\"averages_%s.loc[i,['DayAverages']] =          np.mean(df_loop['%s_days'])\"  % (string, string))    \n",
    "                    exec(\"averages_%s.loc[i,['NightAverages']] =        np.mean(df_loop['%s_nights']) \"  % (string, string))\n",
    "                    exec(\"averages_%s.loc[i,['ratio']] =                np.divide(np.mean(df_loop['%s_days']),np.mean(df_loop['%s_nights']))\"  % (string, string, string))\n",
    "                    exec(\"averages_%s.loc[i,['DayAverages_Masked']] =   np.mean(df_loop['%s_days_masked']) \"  % (string, string))\n",
    "                    exec(\"averages_%s.loc[i,['NightAverages_Masked']] = np.mean(df_loop['%s_nights_masked']) \"  % (string, string))\n",
    "                    exec(\"averages_%s.loc[i,['ratio_Masked']] =         np.divide(np.mean(df_loop['%s_days_masked']),np.mean(df_loop['%s_nights_masked']))\"  % (string, string, string)) \n",
    "                    exec(\"averages_%s.loc[i,['f107']] =                 float(noaa['p107'][date_index])\"  % (string))\n",
    "\n",
    "\n",
    "\n",
    "                i+=1\n",
    "                print(year,'/',day)\n",
    "                # END iday\n",
    "\n",
    "            # END iyear\n",
    "\n",
    "        print(path)\n",
    "        for string in constituents:\n",
    "            exec(\"averages_%s.to_pickle('%s%saverages_%s')\" % (string,path, str(alt), string))\n",
    "\n",
    "\n",
    "\n",
    "def get_GRACE_data(path_grace, year, day):\n",
    "#         path_grace = 'E:/data/day_night_data/GRACE_2002_2012/'\n",
    "    filename = path_grace + '%d/matlab/Density_graceA_3deg_' % year + str(year)[-2:]  +'_%03d.mat' % day\n",
    "#     df = []\n",
    "    # E:\\data\\day_night_data\\GRACE_2002_2012\\2005\\matlab\\Density_graceA_3deg_05_080.mat\n",
    "\n",
    "\n",
    "\n",
    "    status = os.path.exists(filename)\n",
    "\n",
    "    if status == True:\n",
    "        data_grace = loadmat(filename)\n",
    "    elif status == False:\n",
    "        print('No File:', day,'/', year,'N/A', filename )\n",
    "        breakloop = True\n",
    "        df = 0\n",
    "        return(df, breakloop)\n",
    "\n",
    "    data_grace = loadmat(filename)\n",
    "\n",
    "    Version = np.transpose(data_grace['Version']['data'][0][0])[0]\n",
    "    Year = np.transpose(data_grace['Year']['data'][0][0])[0]\n",
    "    Doy = np.transpose(data_grace['Doy']['data'][0][0])[0]\n",
    "    Hours = np.transpose(data_grace['Sec']['data'][0][0])[0]/3600 #in hours\n",
    "    Lon = np.transpose(data_grace['Lon']['data'][0][0])[0]\n",
    "    Lat = np.transpose(data_grace['Lat']['data'][0][0])[0]\n",
    "    LatBin = np.transpose(data_grace['LatBin']['data'][0][0])[0]\n",
    "    Height =  np.transpose(data_grace['Height']['data'][0][0])[0]\n",
    "    LocTim = np.transpose(data_grace['LocTim']['data'][0][0])[0]\n",
    "\n",
    "    Mlat = np.transpose(data_grace['Mlat']['data'][0][0])[0]\n",
    "    Mlon = np.transpose(data_grace['Mlon']['data'][0][0])[0]\n",
    "    Mlt = np.transpose(data_grace['Mlt']['data'][0][0])[0]\n",
    "\n",
    "    Density = np.transpose(data_grace['Density']['data'][0][0])[0]\n",
    "    D400 = np.transpose(data_grace['D400']['data'][0][0])[0]\n",
    "    D410 = np.transpose(data_grace['D410']['data'][0][0])[0]\n",
    "    Dmsis = np.transpose(data_grace['Dmsis']['data'][0][0])[0]\n",
    "\n",
    "    U_rho = np.transpose(data_grace['U_rho']['data'][0][0])[0]\n",
    "    Num = np.transpose(data_grace['Num']['data'][0][0])[0]\n",
    "    NumThrust = np.transpose(data_grace['NumThrust']['data'][0][0])[0]\n",
    "    Cd = np.transpose(data_grace['Cd']['data'][0][0])[0]\n",
    "\n",
    "    df = pd.DataFrame(data ={  'Version' : np.ones(np.transpose(data_grace['Height']['data'][0][0])[0].shape)*Version,\n",
    "                                'Year' : np.ones(np.transpose(data_grace['Height']['data'][0][0])[0].shape)*Year,\n",
    "                                'Doy' : np.ones(np.transpose(data_grace['Height']['data'][0][0])[0].shape)*Doy,\n",
    "                                'Hours' : Hours,\n",
    "                                'Lon' : Lon,\n",
    "                                'Lat' : Lat,\n",
    "                                'LatBin' : LatBin,\n",
    "                                'Height' : Height,\n",
    "                                'LocTim' : LocTim,\n",
    "                                'Mlat' : Mlat,\n",
    "                                'Mlon' : Mlon,\n",
    "                                'Mlt' : Mlt,\n",
    "                                'Density' : Density,\n",
    "                                'D400' : D400,\n",
    "                                'D410' : D410,\n",
    "                                'Dmsis' : Dmsis,\n",
    "                                'U_rho' : U_rho,\n",
    "                                'Num' : Num,\n",
    "                                'NumThrust' : NumThrust,\n",
    "                                'Cd' : Cd,\n",
    "                            } )\n",
    "\n",
    "    print('Loaded data into pandas dataframe')\n",
    "    breakloop = False\n",
    "    return(df, breakloop)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_GRACE_pkl(path_grace, year, day):\n",
    "    filename = path_grace + '%d/matlab/fullpkl_Density_graceA_3deg_' % year + str(year)[-2:]  +'_%03d' % day\n",
    "\n",
    "    status = os.path.exists(filename)\n",
    "\n",
    "    if status == True:\n",
    "        data_grace = pd.read_pickle(filename)\n",
    "\n",
    "    elif status == False:\n",
    "        print('No File:', day,'/', year,'N/A', filename )\n",
    "        breakloop = True\n",
    "        data_grace = 0\n",
    "        return(data_grace, breakloop)\n",
    "\n",
    "    breakloop = False\n",
    "    return(data_grace, breakloop)\n",
    "\n",
    "def make_grace_timeseries(years, days):\n",
    "    tleng = 0\n",
    "    #     dens_sat_full = np.zeros(4*365*1900)\n",
    "    time_full= []\n",
    "#     lon_full= []\n",
    "#     lat_full= []\n",
    "#     slt_full= []\n",
    "#     rho_full = []\n",
    "#     rho_sat_full = []\n",
    "\n",
    "\n",
    "\n",
    "    Version = []\n",
    "    Year = []\n",
    "    Doy = []\n",
    "    Hours = []\n",
    "    Lon = []\n",
    "    Lat = []\n",
    "    LatBin = []\n",
    "    Height = []\n",
    "    LocTim = []\n",
    "    Mlat = []\n",
    "    Mlon = []\n",
    "    Mlt = []\n",
    "    Density = []\n",
    "    D400 = []\n",
    "    D410 = []\n",
    "    Dmsis = []\n",
    "    U_rho = []\n",
    "    Num = []\n",
    "    NumThrust = []\n",
    "    Cd = []\n",
    "    Dmsis_sat = []\n",
    "    Dmsis500 = []\n",
    "    D500 = []\n",
    "    d_n_indicator = []\n",
    "    Ap_dayvals  =[]\n",
    "    f107a_dayvals =[]\n",
    "    f107d_dayvals =[]\n",
    "    p107_dayvals =[]\n",
    "\n",
    "    date = []\n",
    "\n",
    "    time_last_index = np.zeros((np.size(days), np.size(years)))\n",
    "\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for iyear,year in enumerate(years):\n",
    "\n",
    "        for iday,day in enumerate(days):\n",
    "            grace, breakloop = get_GRACE_pkl(year, day) \n",
    "            if breakloop == False:\n",
    "                leng = np.size(grace,0)\n",
    "                date_index = datetime(year, 1, 1) + timedelta(float(day) - 1)    \n",
    "\n",
    "        #         slt = np.zeros(leng)\n",
    "                Ap = float(noaa['Ap'][date_index])\n",
    "                f107a = float(noaa['f107a'][date_index])\n",
    "                f107d = float(noaa['f107d'][date_index])\n",
    "                p107 = float(noaa['p107'][date_index])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # for isat, iheight in enumerate(champ['Height']):\n",
    "                    # find the index of the model data that the satelite is closest to\n",
    "                #     [time_index] = find_min_index(time_model, time_sat[isat])\n",
    "\n",
    "                    # calculate the solar local time in the minimized coords\n",
    "\n",
    "                #     kp_indexed_sat[isat] = data_model['Kp'][time_index][0]\n",
    "                #             date.append( str(year)+'/'+ str(day) + '/' + str(time_sat[isat])[0])\n",
    "                #             date.append(datetime(year, 1, 1) + timedelta(float(day) - 1) + timedelta( hours = time_sat[isat] )) \n",
    "                leng2 = leng+tleng\n",
    "                if i == 0:\n",
    "                     time_full[tleng:leng2] = grace['Hours'][:leng]*3600\n",
    "                else:\n",
    "                    time_full[tleng:leng2] = grace['Hours'][:leng] + time_last_index[iday-1, iyear] \n",
    "\n",
    "\n",
    "#                 slt_full[tleng:leng2]  = grace['LocTim'][:leng] \n",
    "#                 rho_full[tleng:leng2]  = grace['D500'][:leng] \n",
    "#                 rho_sat_full[tleng:leng2]  = grace['Density'][:leng] \n",
    "#                 lon_full[tleng:leng2]  = grace['Lon'][:leng] \n",
    "#                 lat_full[tleng:leng2]  = grace['Lat'][:leng] \n",
    "\n",
    "\n",
    "                Version[tleng:leng2] = grace['Version'][:leng]\n",
    "                Year[tleng:leng2] = grace['Year'][:leng]\n",
    "                Doy[tleng:leng2] = grace['Doy'][:leng]\n",
    "                Hours[tleng:leng2] = grace['Hours'][:leng]\n",
    "                Lon[tleng:leng2] = grace['Lon'][:leng]\n",
    "                Lat[tleng:leng2] = grace['Lat'][:leng]\n",
    "                LatBin[tleng:leng2] = grace['LatBin'][:leng]\n",
    "                Height[tleng:leng2] = grace['Height'][:leng]\n",
    "                LocTim[tleng:leng2] = grace['LocTim'][:leng]\n",
    "                Mlat[tleng:leng2] = grace['Mlat'][:leng]\n",
    "                Mlon[tleng:leng2] = grace['Mlon'][:leng]\n",
    "                Mlt[tleng:leng2] = grace['Mlt'][:leng]\n",
    "                Density[tleng:leng2] = grace['Density'][:leng]\n",
    "                D400[tleng:leng2] = grace['D400'][:leng]\n",
    "                D410[tleng:leng2] = grace['D410'][:leng]\n",
    "                Dmsis[tleng:leng2] = grace['Dmsis'][:leng]\n",
    "                U_rho[tleng:leng2] = grace['U_rho'][:leng]\n",
    "                Num[tleng:leng2] = grace['Num'][:leng]\n",
    "                NumThrust[tleng:leng2] = grace['NumThrust'][:leng]\n",
    "                Cd[tleng:leng2] = grace['Cd'][:leng]\n",
    "                Dmsis_sat[tleng:leng2] = grace['Dmsis_sat'][:leng]\n",
    "                Dmsis500[tleng:leng2] = grace['Dmsis500'][:leng]\n",
    "                D500[tleng:leng2] = grace['D500'][:leng]\n",
    "                d_n_indicator[tleng:leng2] = grace['d_n_indicator'][:leng]\n",
    "#                 Ap_Grace[tleng:leng2] = Ap_dayvals\n",
    "#                 f107a_Grace[tleng:leng2] = f107a_dayvals\n",
    "#                 f107d_Grace[tleng:leng2] = f107d_dayvals\n",
    "#                 p107_Grace[tleng:leng2] = p107_dayvals\n",
    "                Ap_dayvals[tleng:leng2] = np.ones(leng) * Ap\n",
    "                f107a_dayvals[tleng:leng2] = np.ones(leng)* f107a\n",
    "                f107d_dayvals[tleng:leng2] = np.ones(leng)* f107d\n",
    "                p107_dayvals[tleng:leng2] = np.ones(leng) *p107\n",
    "\n",
    "\n",
    "\n",
    "                time_last_index[iday,iyear] = time_full[-1]\n",
    "\n",
    "    #                 time_last_index[iday, iyear] =  champ['time_hours'][-1]\n",
    "                # Kp_model_full[:leng + tleng]   = kp_indexed_sat[:leng]      \n",
    "                for it, itime in enumerate( time_full[tleng:leng2]):\n",
    "#                     print(it,itime)\n",
    "                    date.append(datetime(year, 1, 1) + timedelta( hours = itime )) \n",
    "\n",
    "\n",
    "                tleng = tleng + leng\n",
    "                print(year,'/',day)\n",
    "\n",
    "                i+=1\n",
    "    #             print(np.shape(rho_full))\n",
    "            elif breakloop == True:\n",
    "                i+=1\n",
    "                continue\n",
    "\n",
    "            # END iday\n",
    "        # END iyear\n",
    "\n",
    "#     df = pd.DataFrame(data ={'Date':date  ,\n",
    "#              'D500': rho_full,\n",
    "#              'Dgrace': rho_sat_full,\n",
    "#              'Hours':time_full,\n",
    "#              'LocTim':slt_full, \n",
    "#              'Lon':lon_full,\n",
    "#              'Lat':lat_full\n",
    "#             } )\n",
    "    print(np.shape(d_n_indicator))\n",
    "    print(np.shape(Ap_dayvals))\n",
    "\n",
    "    df = pd.DataFrame(data ={'Date' :date ,\n",
    "                    'time_full'     : time_full,\n",
    "                    'Version'       : Version, \n",
    "                    'Year'          : Year,\n",
    "                    'Doy'           : Doy,\n",
    "                    'Hours'         : Hours,\n",
    "                    'Lon'           : Lon,\n",
    "                    'Lat'           : Lat, \n",
    "                    'LatBin'        : LatBin,\n",
    "                    'Height'        : Height,\n",
    "                    'LocTim'        : LocTim,\n",
    "                    'Mlat'          : Mlat,\n",
    "                    'Mlon'          : Mlon,\n",
    "                    'Mlt'           : Mlt, \n",
    "                    'Density'       : Density,\n",
    "                    'D400'          : D400, \n",
    "                    'D410'          : D410, \n",
    "                    'Dmsis'         : Dmsis,\n",
    "                    'U_rho'         : U_rho,\n",
    "                    'Num'           : Num,\n",
    "                    'NumThrust'     : NumThrust,\n",
    "                    'Cd'            : Cd,\n",
    "                    'Dmsis_sat'     : Dmsis_sat,\n",
    "                    'Dmsis500'      : Dmsis500,\n",
    "                    'D500'          : D500,\n",
    "                    'd_n_indicator' : d_n_indicator,\n",
    "                    'Ap_dayvals'    : Ap_dayvals,\n",
    "                    'f107a_dayvals' : f107a_dayvals,\n",
    "                    'f107d_dayvals' : f107d_dayvals,\n",
    "                    'p107_dayvals'  : p107_dayvals,\n",
    "                  } )\n",
    "\n",
    "    return(df)\n",
    "\n",
    "# path = 'E:/data/day_night_data/GRACE_2002_2012/'\n",
    "\n",
    "\n",
    "# if os.path.exists('E:/data/day_night_data/GRACE_2002_2012/GRACE500km_CombineOrbits.pkl'):\n",
    "#     print('File exists. Hurray!')\n",
    "#     print('E:/data/day_night_data/GRACE_2002_2012/GRACE500km_CombineOrbits')\n",
    "#     Grace500_ts = pd.read_pickle( 'E:/data/day_night_data/GRACE_2002_2012/GRACE500km_CombineOrbits.pkl')  \n",
    "#     pass\n",
    "# else:\n",
    "#     print('Need to combine the separate DataFrames.')\n",
    "#     years =[2002,2003,2004,2005,2006,2007,2008,2009]\n",
    "#     days = np.arange(1,367)\n",
    "\n",
    "#     Grace500_ts = make_grace_timeseries(years, days)\n",
    "#     Grace500_ts.to_pickle( 'E:/data/day_night_data/GRACE_2002_2012/GRACE500km_CombineOrbits.pkl')  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def make_grace_averages():\n",
    "    constituents = ['D500', 'Density', 'LocTim' ]\n",
    "    for string in constituents:\n",
    "\n",
    "        exec(\"averages_%s= pd.DataFrame(data = { 'Date':[], 'Doy':[] ,'DayAverages': [] ,'NightAverages': [] ,'ratio': [],'DayAverages_Masked': [] ,'NightAverages_Masked': [] ,'ratio_Masked': [] ,'f107':[] } )\" % (string))\n",
    "\n",
    "\n",
    "    import os    \n",
    "    filecheck = '500averages_D500'\n",
    "\n",
    "    if os.path.exists( 'E:/data/day_night_data/GRACE_2002_2012/' + filecheck):\n",
    "        print('File exists. Hurray!')\n",
    "        print(path + filecheck)\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        print('File does not exist')\n",
    "        print(path + filecheck)\n",
    "        import pandas as pd\n",
    "        from datetime import datetime\n",
    "        import numpy as np    \n",
    "        import timeit\n",
    "        import time\n",
    "\n",
    "        noaa = pd.read_pickle('E:/data/day_night_data/noaa_2002_2010_pickle' )\n",
    "\n",
    "\n",
    "\n",
    "        years =  [2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009]\n",
    "        days = np.arange(1,366)\n",
    "        i = 0\n",
    "        for iyear,year in enumerate(years):\n",
    "            for iday,day in enumerate(days):\n",
    "\n",
    "                GRACE, breakloop1 = get_GRACE_pkl(year, day)         \n",
    "                if breakloop1 == False:                \n",
    "\n",
    "\n",
    "                    date_index = datetime(year, 1, 1) + timedelta(float(day) - 1)   \n",
    "    #                 loopindex = np.logical_and(Grace500['year'] == year, Grace500['days'] == day )\n",
    "\n",
    "                    mask_day = np.logical_and(GRACE['LocTim'] >= 10.5, GRACE['LocTim'] <= 16.5)\n",
    "                    mask_night = np.logical_or((GRACE['LocTim'] >= 22.5), (GRACE['LocTim'] <= 4.5))  \n",
    "                    mask_lats =  np.logical_and(GRACE['Lat'] <=30 , GRACE['Lat'] >= -30)\n",
    "                    mask_Ap = np.logical_not(float(noaa['Ap'][date_index])>= 15)   \n",
    "\n",
    "    #                 df_loop = pd.DataFrame(data ={\n",
    "    #         #               # Time (for looping)\n",
    "    #                             'D500': Grace500['D500'][loopindex],\n",
    "    #                             'Dgrace' : Grace500['Dgrace'][loopindex],\n",
    "    #                              }, \n",
    "    #                              )\n",
    "\n",
    "\n",
    "                    df_loop = pd.DataFrame(data = {'D500':GRACE['D500'], 'Density':GRACE['Density'], 'Hours':GRACE['Hours'] , 'Days': mask_day,  'Nights':mask_night, 'LocTim':GRACE['LocTim'], 'Doy':GRACE['Doy'] } )\n",
    "\n",
    "                    for string in constituents:\n",
    "                        df_loop.loc[df_loop[string].notnull(), string+'_days'] = (df_loop[string][mask_day])\n",
    "                        df_loop.loc[df_loop[string].notnull(), string+'_nights'] = (df_loop[string][mask_night])\n",
    "                        df_loop.loc[df_loop[string].notnull(), string+'_days_masked'] = (df_loop[string][mask_day & mask_Ap & mask_lats])\n",
    "                        df_loop.loc[df_loop[string].notnull(), string+'_nights_masked'] = (df_loop[string][mask_night & mask_Ap & mask_lats])\n",
    "\n",
    "\n",
    "                    for string in constituents:\n",
    "\n",
    "                        exec(\"averages_%s.loc[i,['Date']] =                 pd.to_datetime(date_index)\"  % (string))\n",
    "                        exec(\"averages_%s.loc[i,['Doy']] =                  np.mean(df_loop['Doy'])\"  % (string))\n",
    "                        exec(\"averages_%s.loc[i,['DayAverages']] =          np.mean(df_loop['%s_days'])\"  % (string, string))    \n",
    "                        exec(\"averages_%s.loc[i,['NightAverages']] =        np.mean(df_loop['%s_nights']) \"  % (string, string))\n",
    "                        exec(\"averages_%s.loc[i,['ratio']] =                np.divide(np.mean(df_loop['%s_days']),np.mean(df_loop['%s_nights']))\"  % (string, string, string))\n",
    "                        exec(\"averages_%s.loc[i,['DayAverages_Masked']] =   np.mean(df_loop['%s_days_masked']) \"  % (string, string))\n",
    "                        exec(\"averages_%s.loc[i,['NightAverages_Masked']] = np.mean(df_loop['%s_nights_masked']) \"  % (string, string))\n",
    "                        exec(\"averages_%s.loc[i,['ratio_Masked']] =         np.divide(np.mean(df_loop['%s_days_masked']),np.mean(df_loop['%s_nights_masked']))\"  % (string, string, string)) \n",
    "                        exec(\"averages_%s.loc[i,['f107']] =                 float(noaa['p107'][date_index])\"  % (string))\n",
    "\n",
    "\n",
    "\n",
    "                    i+=1\n",
    "                    print(year,'/',day)\n",
    "\n",
    "                elif breakloop1 == True:\n",
    "                    i+=1\n",
    "                    continue\n",
    "\n",
    "\n",
    "        print(path)\n",
    "        for string in constituents:\n",
    "            exec(\"averages_%s.to_pickle('%s%saverages_%s')\" % (string,'E:/data/day_night_data/GRACE_2002_2012/', str(500), string))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# path = 'E:/data/day_night_data/GRACE_2002_2012/'\n",
    "# filecheck = '500averages_D500'\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def get_CHAMP_data(path_champ, year, day):\n",
    "    # path_champ = data_path + 'day_night_data/GRACE_2002_2012/'\n",
    "    filename = path_champ + '%d/Density_3deg_' % year + str(year)[-2:]  +'_%03d.mat' % day\n",
    "    #     df = []\n",
    "    # E:\\data\\day_night_data\\GRACE_2002_2012\\2005\\matlab\\Density_graceA_3deg_05_080.mat\n",
    "\n",
    "\n",
    "\n",
    "    status = os.path.exists(filename)\n",
    "\n",
    "    if status == True:\n",
    "        data_champ = loadmat(filename)\n",
    "    elif status == False:\n",
    "        print('No File:', day,'/', year,'N/A', filename )\n",
    "        breakloop = True\n",
    "        df = 0\n",
    "        return(df, breakloop)\n",
    "\n",
    "    data_champ = loadmat(filename)\n",
    "\n",
    "    Version = np.transpose(data_champ['Version']['data'][0][0])[0]\n",
    "    Year = np.transpose(data_champ['Year']['data'][0][0])[0]\n",
    "    Doy = np.transpose(data_champ['Doy']['data'][0][0])[0]\n",
    "    Hours = np.transpose(data_champ['Sec']['data'][0][0])[0]/3600 #in hours\n",
    "    Lon = np.transpose(data_champ['Lon']['data'][0][0])[0]\n",
    "    Lat = np.transpose(data_champ['Lat']['data'][0][0])[0]\n",
    "    LatBin = np.transpose(data_champ['LatBin']['data'][0][0])[0]\n",
    "    Height =  np.transpose(data_champ['Height']['data'][0][0])[0]\n",
    "    LocTim = np.transpose(data_champ['LocTim']['data'][0][0])[0]\n",
    "\n",
    "    Mlat = np.transpose(data_champ['Mlat']['data'][0][0])[0]\n",
    "    Mlon = np.transpose(data_champ['Mlon']['data'][0][0])[0]\n",
    "    Mlt = np.transpose(data_champ['Mlt']['data'][0][0])[0]\n",
    "\n",
    "    Density = np.transpose(data_champ['Density']['data'][0][0])[0]\n",
    "    D400 = np.transpose(data_champ['D400']['data'][0][0])[0]\n",
    "    D410 = np.transpose(data_champ['D410']['data'][0][0])[0]\n",
    "    Dmsis = np.transpose(data_champ['Dmsis']['data'][0][0])[0]\n",
    "\n",
    "    U_rho = np.transpose(data_champ['U_rho']['data'][0][0])[0]\n",
    "    Num = np.transpose(data_champ['Num']['data'][0][0])[0]\n",
    "    NumInterp = np.transpose(data_champ['NumInterp']['data'][0][0])[0]\n",
    "    Cd = np.transpose(data_champ['Cd']['data'][0][0])[0]\n",
    "\n",
    "    df = pd.DataFrame(data ={  'Version' : np.ones(np.transpose(data_champ['Height']['data'][0][0])[0].shape)*Version,\n",
    "                                'Year' : np.ones(np.transpose(data_champ['Height']['data'][0][0])[0].shape)*Year,\n",
    "                                'Doy' : np.ones(np.transpose(data_champ['Height']['data'][0][0])[0].shape)*Doy,\n",
    "                                'Hours' : Hours,\n",
    "                                'Lon' : Lon,\n",
    "                                'Lat' : Lat,\n",
    "                                'LatBin' : LatBin,\n",
    "                                'Height' : Height,\n",
    "                                'LocTim' : LocTim,\n",
    "                                'Mlat' : Mlat,\n",
    "                                'Mlon' : Mlon,\n",
    "                                'Mlt' : Mlt,\n",
    "                                'Density' : Density,\n",
    "                                'D400' : D400,\n",
    "                                'D410' : D410,\n",
    "                                'Dmsis' : Dmsis,\n",
    "                                'U_rho' : U_rho,\n",
    "                                'Num' : Num,\n",
    "                                'NumInterp' : NumInterp,\n",
    "                                'Cd' : Cd,\n",
    "                            } )\n",
    "\n",
    "#     print('Loaded data into pandas dataframe')\n",
    "    breakloop = False\n",
    "    return(df, breakloop)\n",
    "\n",
    "\n",
    "\n",
    "def make_champ_timeseries(path_champ, years, days):\n",
    "    noaa = pd.read_pickle('E:/data/day_night_data/noaa_2002_2010_pickle' )\n",
    "\n",
    "    tleng = 0\n",
    "    #     dens_sat_full = np.zeros(4*365*1900)\n",
    "    time_full= []\n",
    "    #     lon_full= []\n",
    "    #     lat_full= []\n",
    "    #     slt_full= []\n",
    "    #     rho_full = []\n",
    "    #     rho_sat_full = []\n",
    "\n",
    "\n",
    "\n",
    "    Version = []\n",
    "    Year = []\n",
    "    Doy = []\n",
    "    Hours = []\n",
    "    Lon = []\n",
    "    Lat = []\n",
    "    LatBin = []\n",
    "    Height = []\n",
    "    LocTim = []\n",
    "    Mlat = []\n",
    "    Mlon = []\n",
    "    Mlt = []\n",
    "    Density = []\n",
    "    D400 = []\n",
    "    D410 = []\n",
    "    Dmsis = []\n",
    "    U_rho = []\n",
    "    Num = []\n",
    "    NumInterp = []\n",
    "    Cd = []\n",
    "    Dmsis_sat = []\n",
    "    Dmsis500 = []\n",
    "    D500 = []\n",
    "    d_n_indicator = []\n",
    "    Ap_dayvals  =[]\n",
    "    f107a_dayvals =[]\n",
    "    f107d_dayvals =[]\n",
    "    p107_dayvals =[]\n",
    "\n",
    "    date = []\n",
    "\n",
    "    time_last_index = np.zeros((np.size(days), np.size(years)))\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for iyear,year in enumerate(years):\n",
    "\n",
    "        for iday,day in enumerate(days):\n",
    "            champ, breakloop = get_CHAMP_data(path_champ, year, day) \n",
    "            if breakloop == False:\n",
    "                leng = np.size(champ,0)\n",
    "                date_index = datetime(year, 1, 1) + timedelta(float(day)) \n",
    "                Ap = float(noaa['Ap'][date_index])\n",
    "                f107a = float(noaa['f107a'][date_index])\n",
    "                f107d = float(noaa['f107d'][date_index])\n",
    "                p107 = float(noaa['p107'][date_index])\n",
    "                leng2 = leng+tleng\n",
    "    #             if i == 0:\n",
    "    #                  time_full[tleng:leng2] = champ['Hours'][:leng]\n",
    "    #             else:\n",
    "    #                 time_full[tleng:leng2] = champ['Hours'][:leng] + time_last_index[iday, iyear] \n",
    "\n",
    "                Version[tleng:leng2] = champ['Version'][:leng]\n",
    "                Year[tleng:leng2] = champ['Year'][:leng]\n",
    "                Doy[tleng:leng2] = champ['Doy'][:leng]\n",
    "                Hours[tleng:leng2] = champ['Hours'][:leng]\n",
    "                Lon[tleng:leng2] = champ['Lon'][:leng]\n",
    "                Lat[tleng:leng2] = champ['Lat'][:leng]\n",
    "                LatBin[tleng:leng2] = champ['LatBin'][:leng]\n",
    "                Height[tleng:leng2] = champ['Height'][:leng]\n",
    "                LocTim[tleng:leng2] = champ['LocTim'][:leng]\n",
    "                Mlat[tleng:leng2] = champ['Mlat'][:leng]\n",
    "                Mlon[tleng:leng2] = champ['Mlon'][:leng]\n",
    "                Mlt[tleng:leng2] = champ['Mlt'][:leng]\n",
    "                Density[tleng:leng2] = champ['Density'][:leng]\n",
    "                D400[tleng:leng2] = champ['D400'][:leng]\n",
    "                D410[tleng:leng2] = champ['D410'][:leng]\n",
    "                Dmsis[tleng:leng2] = champ['Dmsis'][:leng]\n",
    "                U_rho[tleng:leng2] = champ['U_rho'][:leng]\n",
    "                Num[tleng:leng2] = champ['Num'][:leng]\n",
    "                NumInterp[tleng:leng2] = champ['NumInterp'][:leng]\n",
    "                Cd[tleng:leng2] = champ['Cd'][:leng]\n",
    "                Ap_dayvals[tleng:leng2] = np.ones(leng) * Ap\n",
    "                f107a_dayvals[tleng:leng2] = np.ones(leng)* f107a\n",
    "                f107d_dayvals[tleng:leng2] = np.ones(leng)* f107d\n",
    "                p107_dayvals[tleng:leng2] = np.ones(leng) *p107\n",
    "\n",
    "\n",
    "\n",
    "    #             time_last_index[iday,iyear] = time_full[-1]\n",
    "\n",
    "    #                 time_last_index[iday, iyear] =  champ['time_hours'][-1]\n",
    "                # Kp_model_full[:leng + tleng]   = kp_indexed_sat[:leng]      \n",
    "                for it, itime in enumerate( champ['Hours'][:leng]):\n",
    "    #                     print(it,itime)\n",
    "    #                 print()\n",
    "                    date.append(datetime(year, 1, 1) + timedelta(days = float(day),  hours = itime )) \n",
    "    #             datetime(year, 1, 1) + timedelta(float(day)) \n",
    "\n",
    "\n",
    "                tleng = tleng + leng\n",
    "                print(year,'/',day)\n",
    "\n",
    "                i+=1\n",
    "    #             print(np.shape(rho_full))\n",
    "            elif breakloop == True:\n",
    "                i+=1\n",
    "                continue\n",
    "\n",
    "            # END iday\n",
    "        # END iyear\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(data ={'Date' :date ,\n",
    "    #                 'time_full'     : time_full,\n",
    "                    'Version'       : Version, \n",
    "                    'Year'          : Year,\n",
    "                    'Doy'           : Doy,\n",
    "                    'Hours'         : Hours,\n",
    "                    'Lon'           : Lon,\n",
    "                    'Lat'           : Lat, \n",
    "                    'LatBin'        : LatBin,\n",
    "                    'Height'        : Height,\n",
    "                    'LocTim'        : LocTim,\n",
    "                    'Mlat'          : Mlat,\n",
    "                    'Mlon'          : Mlon,\n",
    "                    'Mlt'           : Mlt, \n",
    "                    'Density'       : Density,\n",
    "                    'D400'          : D400, \n",
    "                    'D410'          : D410, \n",
    "                    'Dmsis'         : Dmsis,\n",
    "                    'U_rho'         : U_rho,\n",
    "                    'Num'           : Num,\n",
    "                    'NumInterp'     : NumInterp,\n",
    "                    'Cd'            : Cd,\n",
    "    #                             'Dmsis_sat'     : Dmsis_sat,\n",
    "    #                             'Dmsis500'      : Dmsis500,\n",
    "    #                             'D500'          : D500,\n",
    "    #                     'd_n_indicator' : d_n_indicator,\n",
    "                    'Ap_dayvals'    : Ap_dayvals,\n",
    "                    'f107a_dayvals' : f107a_dayvals,\n",
    "                    'f107d_dayvals' : f107d_dayvals,\n",
    "                    'p107_dayvals'  : p107_dayvals,\n",
    "                  } )\n",
    "\n",
    "    return(df)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def make_champ_averages(path, filecheck, years, days, alt):\n",
    "    constituents = ['D400', 'Density', 'LocTim' ]\n",
    "    for string in constituents:\n",
    "\n",
    "        exec(\"averages_%s= pd.DataFrame(data = { 'Date':[], 'Doy':[] ,'DayAverages': [] ,'NightAverages': [] ,'ratio': [],'DayAverages_Masked': [] ,'NightAverages_Masked': [] ,'ratio_Masked': [] ,'f107':[] } )\" % (string))\n",
    "\n",
    "\n",
    "    import os    \n",
    "\n",
    "    if os.path.exists( path + filecheck):\n",
    "        print('File exists. Hurray!')\n",
    "        print(path + filecheck)\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        print('File does not exist')\n",
    "        print(path + filecheck)\n",
    "        import pandas as pd\n",
    "        from datetime import datetime\n",
    "        import numpy as np    \n",
    "        import timeit\n",
    "        import time\n",
    "\n",
    "        noaa = pd.read_pickle('E:/data/day_night_data/noaa_2002_2010_pickle' )\n",
    "\n",
    "\n",
    "\n",
    "#             years =  [2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009]\n",
    "#             days = np.arange(1,366)\n",
    "        i = 0\n",
    "        for iyear,year in enumerate(years):\n",
    "            for iday,day in enumerate(days):\n",
    "\n",
    "                champ, breakloop1 = get_CHAMP_data(path,year, day) \n",
    "                if breakloop1 == False:                \n",
    "\n",
    "\n",
    "                    date_index = datetime(year, 1, 1) + timedelta(float(day) - 1)   \n",
    "    #                 loopindex = np.logical_and(Grace500['year'] == year, Grace500['days'] == day )\n",
    "\n",
    "                    mask_day = np.logical_and(champ['LocTim'] >= 10.5, champ['LocTim'] <= 16.5)\n",
    "                    mask_night = np.logical_or((champ['LocTim'] >= 22.5), (champ['LocTim'] <= 4.5))  \n",
    "                    mask_lats =  np.logical_and(champ['Lat'] <=30 , champ['Lat'] >= -30)\n",
    "                    mask_Ap = np.logical_not(float(noaa['Ap'][date_index])>= 15)   \n",
    "\n",
    "    #                 df_loop = pd.DataFrame(data ={\n",
    "    #         #               # Time (for looping)\n",
    "    #                             'D500': Grace500['D500'][loopindex],\n",
    "    #                             'Dgrace' : Grace500['Dgrace'][loopindex],\n",
    "    #                              }, \n",
    "    #                              )\n",
    "\n",
    "\n",
    "                    df_loop = pd.DataFrame(data = {'D400':champ['D400'], 'Density':champ['Density'], 'Hours':champ['Hours'] , 'Days': mask_day,  'Nights':mask_night, 'LocTim':champ['LocTim'], 'Doy':champ['Doy'] } )\n",
    "\n",
    "                    for string in constituents:\n",
    "                        df_loop.loc[df_loop[string].notnull(), string+'_days'] = (df_loop[string][mask_day])\n",
    "                        df_loop.loc[df_loop[string].notnull(), string+'_nights'] = (df_loop[string][mask_night])\n",
    "                        df_loop.loc[df_loop[string].notnull(), string+'_days_masked'] = (df_loop[string][mask_day & mask_Ap & mask_lats])\n",
    "                        df_loop.loc[df_loop[string].notnull(), string+'_nights_masked'] = (df_loop[string][mask_night & mask_Ap & mask_lats])\n",
    "\n",
    "\n",
    "                    for string in constituents:\n",
    "\n",
    "                        exec(\"averages_%s.loc[i,['Date']] =                 pd.to_datetime(date_index)\"  % (string))\n",
    "                        exec(\"averages_%s.loc[i,['Doy']] =                  np.mean(df_loop['Doy'])\"  % (string))\n",
    "                        exec(\"averages_%s.loc[i,['DayAverages']] =          np.mean(df_loop['%s_days'])\"  % (string, string))    \n",
    "                        exec(\"averages_%s.loc[i,['NightAverages']] =        np.mean(df_loop['%s_nights']) \"  % (string, string))\n",
    "                        exec(\"averages_%s.loc[i,['ratio']] =                np.divide(np.mean(df_loop['%s_days']),np.mean(df_loop['%s_nights']))\"  % (string, string, string))\n",
    "                        exec(\"averages_%s.loc[i,['DayAverages_Masked']] =   np.mean(df_loop['%s_days_masked']) \"  % (string, string))\n",
    "                        exec(\"averages_%s.loc[i,['NightAverages_Masked']] = np.mean(df_loop['%s_nights_masked']) \"  % (string, string))\n",
    "                        exec(\"averages_%s.loc[i,['ratio_Masked']] =         np.divide(np.mean(df_loop['%s_days_masked']),np.mean(df_loop['%s_nights_masked']))\"  % (string, string, string)) \n",
    "                        exec(\"averages_%s.loc[i,['f107']] =                 float(noaa['p107'][date_index])\"  % (string))\n",
    "\n",
    "\n",
    "\n",
    "                    i+=1\n",
    "                    print(year,'/',day)\n",
    "\n",
    "                elif breakloop1 == True:\n",
    "                    i+=1\n",
    "                    continue\n",
    "\n",
    "\n",
    "        print(path)\n",
    "        for string in constituents:\n",
    "            exec(\"averages_%s.to_pickle('%s%saverages_%s')\" % (string,path, str(alt), string))    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
